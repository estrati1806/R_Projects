{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b874fb80",
   "metadata": {},
   "source": [
    "# GoodReads List Web Scraper\n",
    "\n",
    "## Description\n",
    "Web scraping is one of the most useful methods to retrieve unstructured data from a website and save them in a structured format. Not all websites allow web scraping, so I decided to work with GoodReads for this project which allows it. \n",
    "\n",
    "This script scrapes details of books from a Goodreads list and outputs the information into to a CSV file.\n",
    "\n",
    "## Libraries\n",
    "The first thing I did was install the required libraries using pip through Command Prompt.\n",
    "1. The **bs4** (BeutifulSoup4) library is a library that makes it easy to scrape information from web pages. It sits atop an HTML or XML parser, providing Python idioms for iterating, searching, and modifying the parse tree.\n",
    "\n",
    "2. The **requests** package is crucial for making HTTP requests to a specified URL, like we do with web scraping. When one makes a request to a URI, it returns a response. GoodReads is a website that allows html web scraping, so it gives a positive response. Many websites do not. \n",
    "\n",
    "3. The **pandas** package will be used to convert the data into a dataframe.\n",
    "    \n",
    "## Example using the first book on the list\n",
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e33169e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd # pandas will be used to compile the data into a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8dba45",
   "metadata": {},
   "source": [
    "### Requesting the website\n",
    "The first element of the scraping function is the **get** function from requests. This makes a request to the website. If the website allows web scraping, we will get a positive \"200\" reponse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f5201fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://www.goodreads.com/list/show/1599.Best_Philosophical_Fiction')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cd5495",
   "metadata": {},
   "source": [
    "### Inspecting the website\n",
    "The list has a total of 3 pages and 281 books in it. Before we scrape all of them, we first need to understand the containers and classes of the data we want to extract by inspecting the webpage's HTML code. We can do so by right-clicking on the element we want to analyze (like the first book on the list) and clicking 'Inspect'. Then, we find the appropriate container and figure out which elements we want from it.\n",
    "\n",
    "For this project, I chose to scrape the book title, author, average rating, number of ratings, votes, and average score (the average score is based on multiple factors, including the number of people who have voted for it and how highly those voters ranked the book). We need to find the class of each element we want to scrape, and specify it in the code. By inspecting the website, we can see that the class for book is named 'bookTitle' and the author class is called 'authorName'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "112b1beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"bookTitle\" href=\"/book/show/49552.The_Stranger\" itemprop=\"url\">\n",
      "<span aria-level=\"4\" itemprop=\"name\" role=\"heading\">The Stranger</span>\n",
      "</a>\n"
     ]
    }
   ],
   "source": [
    "# scraping the first book title\n",
    "soup = bs(response.content, 'html.parser')\n",
    "book_containers = soup.find_all('tr',itemtype=\"http://schema.org/Book\")\n",
    "first_book = book_containers[0]\n",
    "first_book_title = first_book.find('a', class_='bookTitle')\n",
    "print(first_book_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a950e734",
   "metadata": {},
   "source": [
    "This gives us the html code of the book title. To extract the actual title, we use the **text.strip()** function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdcc1152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Stranger\n"
     ]
    }
   ],
   "source": [
    "print(first_book_title.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9739435d",
   "metadata": {},
   "source": [
    "We can do the same for the first book's author, and the container where average rating and number of ratings are stored. Because these 4 are stored in a list, we also need to add the **split()** function to this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "985afd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albert Camus\n",
      "['4.02', 'avg', 'rating', 'â€”', '995,631', 'ratings']\n"
     ]
    }
   ],
   "source": [
    "first_author = first_book.find('a', class_='authorName').text.strip()\n",
    "print(first_author)\n",
    "\n",
    "first_rating = first_book.find('span', class_='minirating').text.strip().split()\n",
    "print(first_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b37f8de",
   "metadata": {},
   "source": [
    "To compile all the data in a csv, we need to break down this array to the elements we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eb81f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Rating: 4.02\n",
      "Ratings: 995,631\n"
     ]
    }
   ],
   "source": [
    "avg_rating = first_rating[0]\n",
    "no_ratings = first_rating[4]\n",
    "print('Average Rating:', avg_rating)\n",
    "print('Ratings:', no_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0684ca1",
   "metadata": {},
   "source": [
    "The last thing we can scrape are the book's overall score on the list and the number of people who voted for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e7fdf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score:', '8,862,', 'and', '90', 'people', 'voted']\n"
     ]
    }
   ],
   "source": [
    "first_score = first_book.find('span', class_='smallText uitext').text.strip().split()\n",
    "print(first_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eca369",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = first_score[1].replace(',','')\n",
    "votes = first_score[3]\n",
    "print('Overall Score:', score) # we remove the commas because a comma is attached to the end of the score\n",
    "print('Number of votes:', votes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7b3c42",
   "metadata": {},
   "source": [
    "## Scraping the whole list\n",
    "Now we are going to put everything together into a function that iterates over all 3 pages and 281 books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "546c752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1\n",
    "title = []\n",
    "author = []\n",
    "avg_rating = []\n",
    "ratings=[]\n",
    "score=[]\n",
    "votes=[]\n",
    "while page != 4:\n",
    "    url = f\"https://www.goodreads.com/list/show/1599.Best_Philosophical_Fiction?page={page}\"\n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.content, 'html.parser')\n",
    "    book_containers = soup.find_all('tr', itemtype=\"http://schema.org/Book\")\n",
    "    for container in book_containers:\n",
    "        titles = container.find('a',class_=\"bookTitle\").text.strip()\n",
    "        title.append(titles)\n",
    "        authors = container.find('a',class_=\"authorName\").text.strip()\n",
    "        author.append(authors)\n",
    "        rating = container.find('span',class_=\"minirating\").text.strip().split()\n",
    "        avg = rating[0]\n",
    "        avg_rating.append(avg)\n",
    "        no = rating[4]\n",
    "        ratings.append(no)\n",
    "        scoring = container.find('span',class_=\"smallText uitext\").text.strip().split()        \n",
    "        scores = scoring[1].replace(',','')\n",
    "        score.append(scores)\n",
    "        vote = scoring[3]\n",
    "        votes.append(vote)\n",
    "    page = page + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2987241d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Stranger Albert Camus 4.02 995,651 8862 90\n"
     ]
    }
   ],
   "source": [
    "# checking if the data was scraped properly\n",
    "print(title[0], author[0], avg_rating[0], ratings[0], score[0], votes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54d88ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    title             author avg_rating    ratings score votes\n",
      "0            The Stranger       Albert Camus       4.02    995,651  8862    90\n",
      "1    Crime and Punishment  Fyodor Dostoevsky       4.26    841,778  7213    73\n",
      "2                    1984      George Orwell       4.19  4,302,165  5727    59\n",
      "3  The Brothers Karamazov  Fyodor Dostoevsky       4.36    312,261  4804    49\n",
      "4              Siddhartha      Hermann Hesse       4.06    734,081  4735    49\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame out of a dictionary\n",
    "books_df = pd.DataFrame({\n",
    "    'title':title, \n",
    "    'author':author,\n",
    "    'avg_rating':avg_rating,\n",
    "    'ratings':ratings,\n",
    "    'score':score,\n",
    "    'votes':votes\n",
    "})\n",
    "\n",
    "print(books_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9664faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "csv_file = 'philosophical_books.csv'\n",
    "books_df.to_csv(csv_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
